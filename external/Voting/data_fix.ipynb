{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e992e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "# Configuration\n",
    "dataset_name = 'products'  # Change to 'arxiv' if needed\n",
    "methods = ['plain', 'linear', 'mlp']  # Methods to process\n",
    "predictions_dir = 'predictions'  # Directory containing prediction files\n",
    "labels_csv = 'gcn_predictions_2.csv'  # CSV file with node_id, prediction, true_label columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b15de14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading true labels from CSV: gcn_predictions_2.csv\n",
      "Loaded 2449029 nodes with 47 classes\n",
      "Node ID range: 0 to 2449028\n",
      "True label range: 0 to 46\n"
     ]
    }
   ],
   "source": [
    "# Load true labels from CSV file\n",
    "print(f\"Loading true labels from CSV: {labels_csv}\")\n",
    "labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "# Verify expected columns\n",
    "expected_cols = ['node_id', 'true_label']\n",
    "if 'true_label' not in labels_df.columns:\n",
    "    # Try alternative column names\n",
    "    if 'truth' in labels_df.columns:\n",
    "        labels_df = labels_df.rename(columns={'truth': 'true_label'})\n",
    "    elif 'label' in labels_df.columns:\n",
    "        labels_df = labels_df.rename(columns={'label': 'true_label'})\n",
    "    else:\n",
    "        raise ValueError(f\"CSV must have 'true_label' column (or 'truth'/'label'). Found: {labels_df.columns.tolist()}\")\n",
    "\n",
    "# Sort by node_id to ensure correct ordering\n",
    "labels_df = labels_df.sort_values('node_id').reset_index(drop=True)\n",
    "\n",
    "# Extract true labels as numpy array\n",
    "true_labels = labels_df['true_label'].values\n",
    "num_nodes = len(true_labels)\n",
    "num_classes = int(true_labels.max() + 1)\n",
    "\n",
    "print(f\"Loaded {num_nodes} nodes with {num_classes} classes\")\n",
    "print(f\"Node ID range: {labels_df['node_id'].min()} to {labels_df['node_id'].max()}\")\n",
    "print(f\"True label range: {true_labels.min()} to {true_labels.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e437d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predictions_file(pred_file, true_labels, method, run_num):\n",
    "    \"\"\"\n",
    "    Process a single prediction file and extract top 3 predictions.\n",
    "    \n",
    "    Args:\n",
    "        pred_file: Path to .pt prediction file\n",
    "        true_labels: Array of true labels for all nodes\n",
    "        method: Method name (for output filename)\n",
    "        run_num: Run number (for output filename)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with node_id, prediction_1, prediction_2, prediction_3, truth\n",
    "    \"\"\"\n",
    "    # Load predictions\n",
    "    predictions = torch.load(pred_file, map_location='cpu')  # Shape: [num_nodes, num_classes]\n",
    "    \n",
    "    # Get top 3 predictions for each node\n",
    "    top3_values, top3_indices = torch.topk(predictions, k=3, dim=1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    top3_indices_np = top3_indices.numpy()  # Shape: [num_nodes, 3]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'node_id': np.arange(num_nodes),\n",
    "        'prediction_1': top3_indices_np[:, 0],\n",
    "        'prediction_2': top3_indices_np[:, 1],\n",
    "        'prediction_3': top3_indices_np[:, 2],\n",
    "        'truth': true_labels\n",
    "    })\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae51440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing plain:\n",
      "  Found 5 prediction file(s)\n",
      "  Processing run 0: predictions/products_plain\\run0.pt\n",
      "    Saved to predictions/products_plain/run0_predictions.csv\n",
      "  Processing run 1: predictions/products_plain\\run1.pt\n",
      "    Saved to predictions/products_plain/run1_predictions.csv\n",
      "  Processing run 2: predictions/products_plain\\run2.pt\n",
      "    Saved to predictions/products_plain/run2_predictions.csv\n",
      "  Processing run 3: predictions/products_plain\\run3.pt\n",
      "    Saved to predictions/products_plain/run3_predictions.csv\n",
      "  Processing run 4: predictions/products_plain\\run4.pt\n",
      "    Saved to predictions/products_plain/run4_predictions.csv\n",
      "\n",
      "Processing linear:\n",
      "  Found 5 prediction file(s)\n",
      "  Processing run 0: predictions/products_linear\\run0.pt\n",
      "    Saved to predictions/products_linear/run0_predictions.csv\n",
      "  Processing run 1: predictions/products_linear\\run1.pt\n",
      "    Saved to predictions/products_linear/run1_predictions.csv\n",
      "  Processing run 2: predictions/products_linear\\run2.pt\n",
      "    Saved to predictions/products_linear/run2_predictions.csv\n",
      "  Processing run 3: predictions/products_linear\\run3.pt\n",
      "    Saved to predictions/products_linear/run3_predictions.csv\n",
      "  Processing run 4: predictions/products_linear\\run4.pt\n",
      "    Saved to predictions/products_linear/run4_predictions.csv\n",
      "\n",
      "Processing mlp:\n",
      "  Found 5 prediction file(s)\n",
      "  Processing run 0: predictions/products_mlp\\run0.pt\n",
      "    Saved to predictions/products_mlp/run0_predictions.csv\n",
      "  Processing run 1: predictions/products_mlp\\run1.pt\n",
      "    Saved to predictions/products_mlp/run1_predictions.csv\n",
      "  Processing run 2: predictions/products_mlp\\run2.pt\n",
      "    Saved to predictions/products_mlp/run2_predictions.csv\n",
      "  Processing run 3: predictions/products_mlp\\run3.pt\n",
      "    Saved to predictions/products_mlp/run3_predictions.csv\n",
      "  Processing run 4: predictions/products_mlp\\run4.pt\n",
      "    Saved to predictions/products_mlp/run4_predictions.csv\n",
      "\n",
      "Processed 15 prediction file(s) total\n"
     ]
    }
   ],
   "source": [
    "# Process all prediction files\n",
    "all_dataframes = []\n",
    "\n",
    "for method in methods:\n",
    "    method_dir = f'{predictions_dir}/{dataset_name}_{method}'\n",
    "    \n",
    "    if not os.path.exists(method_dir):\n",
    "        print(f\"Warning: Directory {method_dir} not found, skipping {method}\")\n",
    "        continue\n",
    "    \n",
    "    # Find all .pt files in the directory\n",
    "    pred_files = glob.glob(f'{method_dir}/*.pt')\n",
    "    pred_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].replace('run', '')))\n",
    "    \n",
    "    print(f\"\\nProcessing {method}:\")\n",
    "    print(f\"  Found {len(pred_files)} prediction file(s)\")\n",
    "    \n",
    "    for pred_file in pred_files:\n",
    "        # Extract run number from filename (e.g., \"run0.pt\" -> 0)\n",
    "        run_num = int(os.path.splitext(os.path.basename(pred_file))[0].replace('run', ''))\n",
    "        \n",
    "        print(f\"  Processing run {run_num}: {pred_file}\")\n",
    "        \n",
    "        # Process the file\n",
    "        df = process_predictions_file(pred_file, true_labels, method, run_num)\n",
    "        \n",
    "        # Add method and run columns for identification\n",
    "        df['method'] = method\n",
    "        df['run'] = run_num\n",
    "        \n",
    "        all_dataframes.append(df)\n",
    "        \n",
    "        # Save individual CSV file\n",
    "        output_file = f'{method_dir}/run{run_num}_predictions.csv'\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"    Saved to {output_file}\")\n",
    "\n",
    "print(f\"\\nProcessed {len(all_dataframes)} prediction file(s) total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14281aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Save combined CSV\u001b[39;00m\n\u001b[32m     10\u001b[39m combined_output = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_all_predictions.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mcombined_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCombined CSV saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\dev\\school\\CSC591 - MLG\\proj\\cns\\CorrectAndSmooth\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:324\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[43mlibwriters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/writers.pyx:73\u001b[39m, in \u001b[36mpandas._libs.writers.write_csv_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Combine all dataframes (optional - if you want one big file)\n",
    "if all_dataframes:\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Reorder columns: node_id, method, run, prediction_1, prediction_2, prediction_3, truth\n",
    "    column_order = ['node_id', 'method', 'run', 'prediction_1', 'prediction_2', 'prediction_3', 'truth']\n",
    "    combined_df = combined_df[column_order]\n",
    "    \n",
    "    # Save combined CSV\n",
    "    combined_output = f'{predictions_dir}/{dataset_name}_all_predictions.csv'\n",
    "    combined_df.to_csv(combined_output, index=False)\n",
    "    print(f\"\\nCombined CSV saved to: {combined_output}\")\n",
    "    print(f\"Shape: {combined_df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(combined_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create separate CSV for each method (without method/run columns)\n",
    "for method in methods:\n",
    "    method_dfs = [df for df in all_dataframes if df['method'].iloc[0] == method]\n",
    "    \n",
    "    if method_dfs:\n",
    "        # If multiple runs, you might want to average or take the first run\n",
    "        # For now, let's take the first run\n",
    "        method_df = method_dfs[0].copy()\n",
    "        \n",
    "        # Remove method and run columns for cleaner output\n",
    "        method_df_clean = method_df[['node_id', 'prediction_1', 'prediction_2', 'prediction_3', 'truth']]\n",
    "        \n",
    "        output_file = f'{predictions_dir}/{dataset_name}_{method}_predictions.csv'\n",
    "        method_df_clean.to_csv(output_file, index=False)\n",
    "        print(f\"Saved {method} predictions to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
